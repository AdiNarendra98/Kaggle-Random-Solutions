{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Shape recognition using LeNet-5 \n* The dataset used in this notebook is [300 images of squares, circles, and triangles](https://www.kaggle.com/datasets/cactus3/basicshapes), uploaded by Mark S on Kaggle.\n","metadata":{}},{"cell_type":"code","source":"# IMPORTING LIBRAIRIES \nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imread","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:14:08.502434Z","iopub.execute_input":"2022-06-30T16:14:08.502738Z","iopub.status.idle":"2022-06-30T16:14:09.014683Z","shell.execute_reply.started":"2022-06-30T16:14:08.502684Z","shell.execute_reply":"2022-06-30T16:14:09.013896Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# DATA PREPROCESSING\ndef rgb_to_gray(rgb):\n# Convert rgb images to gray images\n    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n\n# Create a list with the shape of the images (circles, squares or triangles)\n# and the images\nlst_images = []\n\ndirectories = os.listdir(\"../input/basicshapes/shapes\")\ndirectories.remove(\"shapes\")\n\nfor d in directories:\n    for i in os.listdir(\"../input/basicshapes/shapes/\"+d):\n        img = plt.imread(\"../input/basicshapes/shapes/\"+d+\"/\"+i)\n        img = rgb_to_gray(img)\n        # Reshape the images to 28x28x1 for the neural network\n        img = np.array(img).reshape(28,28,1)\n        lst_images.append([d,img])","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:14:50.688587Z","iopub.execute_input":"2022-06-30T16:14:50.688913Z","iopub.status.idle":"2022-06-30T16:14:50.901777Z","shell.execute_reply.started":"2022-06-30T16:14:50.688882Z","shell.execute_reply":"2022-06-30T16:14:50.901101Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Shuffling the list to make the training more effective\nimport random\nrandom.shuffle(lst_images)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:14:52.003539Z","iopub.execute_input":"2022-06-30T16:14:52.003853Z","iopub.status.idle":"2022-06-30T16:14:52.008625Z","shell.execute_reply.started":"2022-06-30T16:14:52.003823Z","shell.execute_reply":"2022-06-30T16:14:52.007858Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Separate the images from the labels\n# Rename the labels into:\n# squares => 0\n# circles => 1\n# triangles => 2\nX = []\ny = []\nfor i in range(len(lst_images)):\n    X.append(lst_images[i][1])\n    \n    yi = lst_images[i][0]\n    if yi == \"squares\":\n        y.append(0)\n    elif yi == \"circles\":\n        y.append(1)\n    else:\n        y.append(2)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:14:52.924510Z","iopub.execute_input":"2022-06-30T16:14:52.924858Z","iopub.status.idle":"2022-06-30T16:14:52.931310Z","shell.execute_reply.started":"2022-06-30T16:14:52.924823Z","shell.execute_reply":"2022-06-30T16:14:52.930190Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# IMAGE VISUALIZATIONS\nfor i in range(3):\n    plt.imshow(X[i].reshape(28,28))\n    plt.title(lst_images[i][0], fontsize =18)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:14:54.515568Z","iopub.execute_input":"2022-06-30T16:14:54.515924Z","iopub.status.idle":"2022-06-30T16:14:55.134485Z","shell.execute_reply.started":"2022-06-30T16:14:54.515886Z","shell.execute_reply":"2022-06-30T16:14:55.133729Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Convert the labels y with to_categorical for the neural network\n# Example: [2,1] => [[0,0,1],[0,1,0]]\nfrom tensorflow.keras.utils import to_categorical\ny = to_categorical(y)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:15:18.706692Z","iopub.execute_input":"2022-06-30T16:15:18.706986Z","iopub.status.idle":"2022-06-30T16:15:25.147054Z","shell.execute_reply.started":"2022-06-30T16:15:18.706958Z","shell.execute_reply":"2022-06-30T16:15:25.146331Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# TRAIN TEST SPLIT\nfrom sklearn.model_selection import train_test_split\nX = np.array(X)\ny = np.array(y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:15:33.867112Z","iopub.execute_input":"2022-06-30T16:15:33.867428Z","iopub.status.idle":"2022-06-30T16:15:34.043469Z","shell.execute_reply.started":"2022-06-30T16:15:33.867399Z","shell.execute_reply":"2022-06-30T16:15:34.042643Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# LeNet-5 Architecture<a class=\"anchor\" id=\"2\"></a>\n<img src=\"https://i.imgur.com/PNyzJWo.png\">\nOriginal Image published in [LeCun et al., 1998]","metadata":{}},{"cell_type":"code","source":"# BUILDING THE LeNet-5 MODEL\nimport tensorflow.keras\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D, BatchNormalization, AveragePooling2D\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ndef from_categorical(lst):\n    \"\"\"\n    Inverse of to_categorical\n    Example: [[0,0,0,1,0], [1,0,0,0,0]] => [3,0]\n    \"\"\"\n    \n    lst = lst.tolist()\n    lst2 = []\n    for x in lst:\n        lst2.append(x.index(max(x)))\n    return lst2\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:16:31.864328Z","iopub.execute_input":"2022-06-30T16:16:31.864603Z","iopub.status.idle":"2022-06-30T16:16:31.879280Z","shell.execute_reply.started":"2022-06-30T16:16:31.864574Z","shell.execute_reply":"2022-06-30T16:16:31.878157Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def LeNet(Conv2D_filters = 128, \n          validation_split = 0.2,\n          X_train = X_train, \n          X_test = X_test, \n          y_train = y_train, \n          y_test = y_test):\n    \n    # Create the LeNet model \n    model = Sequential()\n    model.add(Conv2D(filters=Conv2D_filters, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n    model.add(MaxPooling2D())\n    model.add(Conv2D(filters=Conv2D_filters*2, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D())\n    model.add(Flatten())\n    model.add(Dense(units=120, activation='relu'))\n    model.add(Dense(units=84, activation='relu'))\n    model.add(Dense(units=3, activation = 'softmax'))\n    \n    # Compile and train the model\n    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n    model.fit(x = X_train, y = y_train, batch_size = 128, epochs = 100, verbose = 0, validation_split = validation_split)\n    \n    # Display the results\n    # print(\"################### New model ###################\")\n    length = len(model.history.history[\"accuracy\"])\n    plt.plot(np.arange(0, length), model.history.history[\"accuracy\"], label=\"accuracy\")\n    \n    # Display the validation results only if there is a validation split\n    if validation_split > 0:\n        plt.plot(np.arange(0, length), model.history.history[\"val_accuracy\"], label=\"val_accuracy\")\n        plt.title(f\"Accuracy & Validation accuracy\\nNumber of Conv. filters: {Conv2D_filters}\")\n    else:\n        plt.title(f\"Accuracy\\nNumber of Conv. filters: {Conv2D_filters}\")\n        \n    plt.xlabel(\"Epoch #\")\n    plt.show()\n\n    y_test2 = from_categorical(y_test)\n    pred = model.predict_classes(X_test)\n\n    print(\"### Test-set ###\\n\\nConfusion Matrix:\\n\")\n    print(confusion_matrix(y_test2,pred))\n    print(f\"\\nAccuracy: {accuracy_score(y_test2,pred)}\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:16:35.078825Z","iopub.execute_input":"2022-06-30T16:16:35.079102Z","iopub.status.idle":"2022-06-30T16:16:35.093735Z","shell.execute_reply.started":"2022-06-30T16:16:35.079074Z","shell.execute_reply":"2022-06-30T16:16:35.092726Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Trying different number of filters [16, 32, 64, 128] for the conventional layer to see which one gives the best results.\nfor f in [2**x for x in range(4,8)]:\n    LeNet(f)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:17:06.569711Z","iopub.execute_input":"2022-06-30T16:17:06.570107Z","iopub.status.idle":"2022-06-30T16:17:23.489853Z","shell.execute_reply.started":"2022-06-30T16:17:06.570064Z","shell.execute_reply":"2022-06-30T16:17:23.488427Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = LeNet(64, 0)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:17:28.513438Z","iopub.execute_input":"2022-06-30T16:17:28.514049Z","iopub.status.idle":"2022-06-30T16:17:31.155016Z","shell.execute_reply.started":"2022-06-30T16:17:28.513998Z","shell.execute_reply":"2022-06-30T16:17:31.154232Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#DATA AUGUMENTATION(For Accuracy Improval)\n# Rotating an image\nimg = X_train[2]\nfor i in range(0,4):\n    plt.figure(figsize = (3,3))\n    plt.title(f\"Rotate image by {i*90} degree\")\n    plt.imshow(np.rot90(img,i).reshape(28,28))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:18:27.223081Z","iopub.execute_input":"2022-06-30T16:18:27.223383Z","iopub.status.idle":"2022-06-30T16:18:27.680270Z","shell.execute_reply.started":"2022-06-30T16:18:27.223353Z","shell.execute_reply":"2022-06-30T16:18:27.679671Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Generate new data\n# Create a list with the original train data and the new ones\nX_train_gener = []\ny_train_gener = []\nfor i in range(len(X_train)):\n    img = X_train[i]\n    for r in range(4):\n        img = np.rot90(img,r)\n        X_train_gener.append(img)\n        y_train_gener.append(y_train[i])\n\n# Shuffle the picture and the label on a deterministic way\nrandom.Random(0).shuffle(X_train_gener) \nrandom.Random(0).shuffle(y_train_gener) \n\nX_train_gener = np.array(X_train_gener)\ny_train_gener = np.array(y_train_gener)\n\nprint(f\"Total number of training data: {len(X_train_gener)}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:18:28.605004Z","iopub.execute_input":"2022-06-30T16:18:28.605291Z","iopub.status.idle":"2022-06-30T16:18:28.645720Z","shell.execute_reply.started":"2022-06-30T16:18:28.605262Z","shell.execute_reply":"2022-06-30T16:18:28.644867Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = LeNet(64, 0.2, X_train=X_train_gener, y_train = y_train_gener)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:19:56.155374Z","iopub.execute_input":"2022-06-30T16:19:56.155645Z","iopub.status.idle":"2022-06-30T16:20:01.819982Z","shell.execute_reply.started":"2022-06-30T16:19:56.155618Z","shell.execute_reply":"2022-06-30T16:20:01.819303Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}