{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **PARKISNSON'S CLASSIFIER USING VARIOUS MODELS**\nThe dataset used is [Parkinson Disease Detection](https://www.kaggle.com/datasets/debasisdotcom/parkinson-disease-detection),from Kaggle uploaded by Debasis Samal.","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:04:46.954517Z","iopub.execute_input":"2022-06-22T07:04:46.954909Z","iopub.status.idle":"2022-06-22T07:04:46.963059Z","shell.execute_reply.started":"2022-06-22T07:04:46.954877Z","shell.execute_reply":"2022-06-22T07:04:46.961377Z"}}},{"cell_type":"code","source":"# IMPORT LIBRARIES AND LOAD DATASET\nimport numpy as np\nimport seaborn as sns  \nimport matplotlib.pyplot as plt   \nimport warnings # to ignore warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd # data processing,\ndf = pd.read_csv(\"../input/parkinson-disease-detection/Parkinsson disease.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:15.028859Z","iopub.execute_input":"2022-06-22T07:05:15.029274Z","iopub.status.idle":"2022-06-22T07:05:15.045916Z","shell.execute_reply.started":"2022-06-22T07:05:15.029243Z","shell.execute_reply":"2022-06-22T07:05:15.044687Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# Displaying the head of the dataset\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:15.928868Z","iopub.execute_input":"2022-06-22T07:05:15.929535Z","iopub.status.idle":"2022-06-22T07:05:15.980181Z","shell.execute_reply.started":"2022-06-22T07:05:15.929498Z","shell.execute_reply":"2022-06-22T07:05:15.978803Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Displaying the shape and datatype for each attribute\n\nprint('Shape of the dataset: ',df.shape,'\\n\\n')\n\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:16.148827Z","iopub.execute_input":"2022-06-22T07:05:16.149245Z","iopub.status.idle":"2022-06-22T07:05:16.173584Z","shell.execute_reply.started":"2022-06-22T07:05:16.149207Z","shell.execute_reply":"2022-06-22T07:05:16.172153Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Dispalying the descriptive statistics describe each attribute\n\ndf.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:16.419411Z","iopub.execute_input":"2022-06-22T07:05:16.419892Z","iopub.status.idle":"2022-06-22T07:05:16.500401Z","shell.execute_reply.started":"2022-06-22T07:05:16.419852Z","shell.execute_reply":"2022-06-22T07:05:16.499132Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"Almost all the columns' mean is greater than the median(50%).\nThe mean is greater we can say that there are more number of columns are highly skewed to the right.\n\n\n","metadata":{}},{"cell_type":"code","source":"# Checking Null or Empty Values\n\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:16.813512Z","iopub.execute_input":"2022-06-22T07:05:16.813990Z","iopub.status.idle":"2022-06-22T07:05:16.824089Z","shell.execute_reply.started":"2022-06-22T07:05:16.813948Z","shell.execute_reply":"2022-06-22T07:05:16.823166Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"df = df.drop('name',1)  # as we said earlier dropping the 'name' column as it is not significant for model building","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:16.983864Z","iopub.execute_input":"2022-06-22T07:05:16.984226Z","iopub.status.idle":"2022-06-22T07:05:16.991165Z","shell.execute_reply.started":"2022-06-22T07:05:16.984196Z","shell.execute_reply":"2022-06-22T07:05:16.989674Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"### Univariate analysis","metadata":{}},{"cell_type":"code","source":"# Plotting histogram of the columns to study the data distribution\nk=1\nplt.figure(figsize=(26,30))\n\n# using for loop to iterate over all the columns in the dataframe and plot the histogram of those\n\nfor col in df.columns[0:]:\n    plt.subplot(6,4,k)\n    plt.hist(df[col],color='lightblue', edgecolor = 'black', alpha = 0.5)\n#     sns.distplot(df[col],kde=False)\n    plt.title(col)\n    k=k+1","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:18.404175Z","iopub.execute_input":"2022-06-22T07:05:18.404537Z","iopub.status.idle":"2022-06-22T07:05:22.809884Z","shell.execute_reply.started":"2022-06-22T07:05:18.404507Z","shell.execute_reply":"2022-06-22T07:05:22.808672Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"### Bivariate analysis","metadata":{}},{"cell_type":"code","source":"# Using histogrm from seaborn plotting of spread1 for status column\n\nsns.distplot( df[df.status == 0]['spread1'],color='blue'); # spread1 for who are normal\nsns.distplot( df[df.status == 1]['spread1'],color='yellow'); # spread1 for who have PD","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:26.175488Z","iopub.execute_input":"2022-06-22T07:05:26.175886Z","iopub.status.idle":"2022-06-22T07:05:26.420119Z","shell.execute_reply.started":"2022-06-22T07:05:26.175854Z","shell.execute_reply":"2022-06-22T07:05:26.418759Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2,figsize=(14,6))\n\n# Bivariate Boxplot to see the difference between NHR and HNR\nsns.boxplot(x=df['status'],y=df['NHR'],ax=ax[0]);   # boxplot of status Vs NHR\nsns.boxplot(x=df['status'],y=df['HNR'],ax=ax[1]);   # boxplot of status Vs NHR","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:27.230128Z","iopub.execute_input":"2022-06-22T07:05:27.230698Z","iopub.status.idle":"2022-06-22T07:05:27.536569Z","shell.execute_reply.started":"2022-06-22T07:05:27.230660Z","shell.execute_reply":"2022-06-22T07:05:27.535415Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nplt.pie(df.status.value_counts(),colors=['lightgreen','yellow'],explode=[0,0.02],autopct='%1.0f%%',labels=['0(healthy)',\"1(parkinson's)\"]);","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:27.577226Z","iopub.execute_input":"2022-06-22T07:05:27.577791Z","iopub.status.idle":"2022-06-22T07:05:27.685892Z","shell.execute_reply.started":"2022-06-22T07:05:27.577754Z","shell.execute_reply":"2022-06-22T07:05:27.684592Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"**Ratio of Healthy Patients to Parkison's Patients is 75:25**","metadata":{}},{"cell_type":"code","source":"# checking the correlation of dataset \nfig, ax = plt.subplots(figsize=(20, 20))\nax = sns.heatmap(df.corr(),cmap=\"mako\",square=True,annot = True,linewidth=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:28.601099Z","iopub.execute_input":"2022-06-22T07:05:28.601524Z","iopub.status.idle":"2022-06-22T07:05:32.242409Z","shell.execute_reply.started":"2022-06-22T07:05:28.601485Z","shell.execute_reply":"2022-06-22T07:05:32.240947Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"correlation_values=df.corr()['status']\npd.DataFrame(correlation_values.sort_values(ascending=False))","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:34.068570Z","iopub.execute_input":"2022-06-22T07:05:34.069125Z","iopub.status.idle":"2022-06-22T07:05:34.083502Z","shell.execute_reply.started":"2022-06-22T07:05:34.069092Z","shell.execute_reply":"2022-06-22T07:05:34.082701Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# Train-Test Split\nfrom sklearn.model_selection import train_test_split\n\nX = df.drop('status',1)  # predictors\ny = df.status            # target attributez\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)  # making 70:30 split\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:34.891190Z","iopub.execute_input":"2022-06-22T07:05:34.891749Z","iopub.status.idle":"2022-06-22T07:05:34.903739Z","shell.execute_reply.started":"2022-06-22T07:05:34.891708Z","shell.execute_reply":"2022-06-22T07:05:34.902566Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nrc = MinMaxScaler() # instantiating the object for minmaxscaler\n\ncolumns = list(X_train.columns)  # storing the columns\n\nX_train_scaled = pd.DataFrame(rc.fit_transform(X_train))\nX_train_scaled.columns = columns  # assigning the columns after scaling the values\n\nX_test_scaled = pd.DataFrame(rc.fit_transform(X_test))\nX_test_scaled.columns = columns  # assigning the columns after scaling the values","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:35.604294Z","iopub.execute_input":"2022-06-22T07:05:35.604766Z","iopub.status.idle":"2022-06-22T07:05:35.621996Z","shell.execute_reply.started":"2022-06-22T07:05:35.604728Z","shell.execute_reply":"2022-06-22T07:05:35.620958Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# **Logistic Regression is a classification algorithm. \n# **It is used to predict a binary outcome (1 / 0, Yes / No, True / False) given a set of independent variables,\n\nfrom sklearn.linear_model import LogisticRegression\n\n# create an instance for LogisticRegression\nLogistic = LogisticRegression(solver=\"liblinear\")\n\n# fit the model\nLogistic.fit(X_train_scaled, y_train)\n\n# predict on created model\nl_predict = Logistic.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:37.476303Z","iopub.execute_input":"2022-06-22T07:05:37.477066Z","iopub.status.idle":"2022-06-22T07:05:37.489145Z","shell.execute_reply.started":"2022-06-22T07:05:37.477021Z","shell.execute_reply":"2022-06-22T07:05:37.487772Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# checking the score of the testset\nacc_logistic_test = Logistic.score(X_test_scaled, y_test)*100","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:38.864899Z","iopub.execute_input":"2022-06-22T07:05:38.865278Z","iopub.status.idle":"2022-06-22T07:05:38.872989Z","shell.execute_reply.started":"2022-06-22T07:05:38.865245Z","shell.execute_reply":"2022-06-22T07:05:38.871940Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# storing accuracy results of each model in the dataframe for final comparision \nresult_df = pd.DataFrame({'Model': ['Logistic Regression'], 'Accuracy' : [acc_logistic_test]}).drop_duplicates()\nresult_df","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:44.430092Z","iopub.execute_input":"2022-06-22T07:05:44.430865Z","iopub.status.idle":"2022-06-22T07:05:44.447076Z","shell.execute_reply.started":"2022-06-22T07:05:44.430806Z","shell.execute_reply":"2022-06-22T07:05:44.446183Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# Naive Bayes Classifier\n# Bayes Theorem assumes predictors or input features are independent of each other,\n\nfrom sklearn.naive_bayes import GaussianNB # using Gaussian algorithm from Naive Bayes as all the columns are numerical\n\n# create an instance for GaussianNB\nn_model = GaussianNB()\n\n# fit the model\nn_model.fit(X_train_scaled, y_train)\n\n# prediction using created model\nn_predict = n_model.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:45.485021Z","iopub.execute_input":"2022-06-22T07:05:45.485727Z","iopub.status.idle":"2022-06-22T07:05:45.498113Z","shell.execute_reply.started":"2022-06-22T07:05:45.485665Z","shell.execute_reply":"2022-06-22T07:05:45.497066Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# checking the score of the test set\nacc_naive_test = n_model.score(X_test_scaled, y_test)*100","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:05:46.257920Z","iopub.execute_input":"2022-06-22T07:05:46.258375Z","iopub.status.idle":"2022-06-22T07:05:46.266408Z","shell.execute_reply.started":"2022-06-22T07:05:46.258333Z","shell.execute_reply":"2022-06-22T07:05:46.265508Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# storing accuracy results of each model in the dataframe for final comparision\ntempResult_df = pd.DataFrame({'Model': ['Naive Bayes'], 'Accuracy' : [acc_naive_test]})\nresult_df = pd.concat([result_df,tempResult_df]).drop_duplicates()\nresult_df","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:13.498840Z","iopub.execute_input":"2022-06-22T07:06:13.499330Z","iopub.status.idle":"2022-06-22T07:06:13.515853Z","shell.execute_reply.started":"2022-06-22T07:06:13.499289Z","shell.execute_reply":"2022-06-22T07:06:13.514842Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# KNN Classifier(K-Nearest Neighberhood Classifier)\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# create instance for KNeighborsClassifier and using k value = 5\nknn_model = KNeighborsClassifier(n_neighbors=5)\n\n# fit the model\nknn_model.fit(X_train_scaled, y_train)\n\n# prediction using created model\nknn_predict = knn_model.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:14.338499Z","iopub.execute_input":"2022-06-22T07:06:14.339098Z","iopub.status.idle":"2022-06-22T07:06:14.356762Z","shell.execute_reply.started":"2022-06-22T07:06:14.339058Z","shell.execute_reply":"2022-06-22T07:06:14.355698Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"# checking the score of the test set\nacc_knn_test = knn_model.score(X_test_scaled, y_test)*100 ","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:15.191805Z","iopub.execute_input":"2022-06-22T07:06:15.192573Z","iopub.status.idle":"2022-06-22T07:06:15.206440Z","shell.execute_reply.started":"2022-06-22T07:06:15.192517Z","shell.execute_reply":"2022-06-22T07:06:15.205363Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# Storing accuracy results of each model in the dataframe for final comparision \ntempResult_df = pd.DataFrame({'Model': ['KNN Scaled'], 'Accuracy' : [acc_knn_test]})\nresult_df = pd.concat([result_df,tempResult_df]).drop_duplicates()\nresult_df\n\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-22T07:06:36.329015Z","iopub.execute_input":"2022-06-22T07:06:36.329727Z","iopub.status.idle":"2022-06-22T07:06:36.346249Z","shell.execute_reply.started":"2022-06-22T07:06:36.329686Z","shell.execute_reply":"2022-06-22T07:06:36.345284Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# Decision tree algorithm falls under the category of supervised learning. \n# Decision tree uses the tree representation to solve the problem in which each leaf node corresponds to a class label and attributes are represented on the internal node of the tree\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n# using entropy technique we are making splits\ndecision_tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 6, random_state = 100) \n\n# fitting the model\ndecision_tree.fit(X_train_scaled, y_train) \n\n# predicting the model on test set\nd_pred = decision_tree.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:37.962274Z","iopub.execute_input":"2022-06-22T07:06:37.962710Z","iopub.status.idle":"2022-06-22T07:06:37.974436Z","shell.execute_reply.started":"2022-06-22T07:06:37.962676Z","shell.execute_reply":"2022-06-22T07:06:37.973662Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# checking the score of the testset\nacc_DT_test = decision_tree.score(X_test_scaled, y_test)*100","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:38.626275Z","iopub.execute_input":"2022-06-22T07:06:38.626663Z","iopub.status.idle":"2022-06-22T07:06:38.634069Z","shell.execute_reply.started":"2022-06-22T07:06:38.626632Z","shell.execute_reply":"2022-06-22T07:06:38.633039Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# storing accuracy results of each model in the dataframe for final comparision \ntempResult_df = pd.DataFrame({'Model': ['Decision Tree'], 'Accuracy' : acc_DT_test})\nresult_df = pd.concat([result_df,tempResult_df])\nresult_df","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:39.607465Z","iopub.execute_input":"2022-06-22T07:06:39.608103Z","iopub.status.idle":"2022-06-22T07:06:39.622835Z","shell.execute_reply.started":"2022-06-22T07:06:39.608058Z","shell.execute_reply":"2022-06-22T07:06:39.621831Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"#META CLASSIFIER PACKAGE\nfrom mlxtend.classifier import StackingClassifier  # importing stacking classifier package\n#Type of A Ensemble Technique with Mutliple Classifiers","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:40.638042Z","iopub.execute_input":"2022-06-22T07:06:40.638607Z","iopub.status.idle":"2022-06-22T07:06:40.642209Z","shell.execute_reply.started":"2022-06-22T07:06:40.638555Z","shell.execute_reply":"2022-06-22T07:06:40.641469Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC  # importing SVM classifier\n\n# creating four individual classification models\nmodel1 = DecisionTreeClassifier(criterion = 'entropy',max_depth = 6)\nmodel2 = KNeighborsClassifier(n_neighbors=5)\nmodel3 = GaussianNB()\nmodel4 = SVC(C = 10,gamma=0.01)\n\n# giving logistic regression as meta classifier/model\nmeta_model = LogisticRegression()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:42.009337Z","iopub.execute_input":"2022-06-22T07:06:42.009915Z","iopub.status.idle":"2022-06-22T07:06:42.015947Z","shell.execute_reply.started":"2022-06-22T07:06:42.009863Z","shell.execute_reply":"2022-06-22T07:06:42.014745Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# calling stacking classifier with all the base models and meta model\nstcl = StackingClassifier(classifiers = [model1,model2,model3,model4], meta_classifier = meta_model)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:43.338019Z","iopub.execute_input":"2022-06-22T07:06:43.338698Z","iopub.status.idle":"2022-06-22T07:06:43.343979Z","shell.execute_reply.started":"2022-06-22T07:06:43.338657Z","shell.execute_reply":"2022-06-22T07:06:43.342963Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# loop through all the models created with meta model\nfor models, label in zip ([model1,model2,model3,model4, stcl], ['DecisionTreeClassifier','KNN','NaiveBayes','SVM','StackingClassifier']):\n    \n    scores = cross_val_score (models, X, y, cv=10, scoring='accuracy')\n    print(scores,label)\n#     print(\"Accuracy:\",scores.mean(),label)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:44.563661Z","iopub.execute_input":"2022-06-22T07:06:44.564277Z","iopub.status.idle":"2022-06-22T07:06:45.438836Z","shell.execute_reply.started":"2022-06-22T07:06:44.564239Z","shell.execute_reply":"2022-06-22T07:06:45.436890Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# storing accuracy results of each model in the dataframe for final comparision \ntempResult_df = pd.DataFrame({'Model': ['Stacking Classifier'], 'Accuracy' : scores.mean()*100})\nresult_df = pd.concat([result_df,tempResult_df])\nresult_df","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:45.781993Z","iopub.execute_input":"2022-06-22T07:06:45.782399Z","iopub.status.idle":"2022-06-22T07:06:45.799856Z","shell.execute_reply.started":"2022-06-22T07:06:45.782365Z","shell.execute_reply":"2022-06-22T07:06:45.798602Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"# RANDOM FORESTS - ENSEMBLE TECHNIQUE\nfrom sklearn.ensemble import RandomForestClassifier  # importing random forest classifier\n\nrfcl = RandomForestClassifier() # calling the randomforest with 20 decision trees\nrfcl = rfcl.fit(X_train_scaled, y_train)  # fitting the model","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:46.702673Z","iopub.execute_input":"2022-06-22T07:06:46.703024Z","iopub.status.idle":"2022-06-22T07:06:46.910846Z","shell.execute_reply.started":"2022-06-22T07:06:46.702994Z","shell.execute_reply":"2022-06-22T07:06:46.909490Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"rfcl.score(X_test_scaled, y_test)  # score of train and test set","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:47.872926Z","iopub.execute_input":"2022-06-22T07:06:47.873278Z","iopub.status.idle":"2022-06-22T07:06:47.892785Z","shell.execute_reply.started":"2022-06-22T07:06:47.873248Z","shell.execute_reply":"2022-06-22T07:06:47.891105Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"# Importing classification report and confusion matrix from sklearn metrics\nfrom sklearn.metrics import classification_report,confusion_matrix, accuracy_score\nrf_pred = rfcl.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:48.811346Z","iopub.execute_input":"2022-06-22T07:06:48.811874Z","iopub.status.idle":"2022-06-22T07:06:48.831326Z","shell.execute_reply.started":"2022-06-22T07:06:48.811841Z","shell.execute_reply":"2022-06-22T07:06:48.830493Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# Let's check the report of our default model\nprint(classification_report(y_test,rf_pred))","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:49.659047Z","iopub.execute_input":"2022-06-22T07:06:49.659675Z","iopub.status.idle":"2022-06-22T07:06:49.672098Z","shell.execute_reply.started":"2022-06-22T07:06:49.659606Z","shell.execute_reply":"2022-06-22T07:06:49.670599Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# Printing the accuracy score of actual values and predictions\nacc_rf = accuracy_score(y_test,rf_pred)*100\nprint('Accuracy score of Random Forest Classifier: ',acc_rf,'%','\\n')\n\n# Printing confusion matrix\ncm = confusion_matrix(y_test,rf_pred)\n\ndf1 = pd.DataFrame(cm,columns=['No','Yes'], index = ['No','Yes'])\nprint('\\t\\tConfusion matrix')\nsns.heatmap(df1,annot=True,cbar=False);","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:50.536302Z","iopub.execute_input":"2022-06-22T07:06:50.536705Z","iopub.status.idle":"2022-06-22T07:06:50.653864Z","shell.execute_reply.started":"2022-06-22T07:06:50.536673Z","shell.execute_reply":"2022-06-22T07:06:50.652112Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:51.450611Z","iopub.execute_input":"2022-06-22T07:06:51.451003Z","iopub.status.idle":"2022-06-22T07:06:51.462095Z","shell.execute_reply.started":"2022-06-22T07:06:51.450971Z","shell.execute_reply":"2022-06-22T07:06:51.461116Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# storing accuracy results of each model in the dataframe for final comparision\ntempResult_df = pd.DataFrame({'Model': ['Random Forest'], 'Accuracy' : acc_rf})\nresult_df = pd.concat([result_df,tempResult_df]).drop_duplicates()\nresult_df","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:52.212875Z","iopub.execute_input":"2022-06-22T07:06:52.213314Z","iopub.status.idle":"2022-06-22T07:06:52.231467Z","shell.execute_reply.started":"2022-06-22T07:06:52.213274Z","shell.execute_reply":"2022-06-22T07:06:52.230515Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"# GRID SEARCH CV FOR OPTIMAL HYPERPARAMETERS FINDINGS\n# Creating the parameter grid based on the results of random search \nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'max_depth': [2,4,8,10],\n    'n_estimators': [50,100,200, 300], \n    'max_features': [5, 10, 15]\n    }\n\n# Create a base model\nrf = RandomForestClassifier(random_state=100)\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1,verbose = 1,scoring='accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:06:52.980881Z","iopub.execute_input":"2022-06-22T07:06:52.981319Z","iopub.status.idle":"2022-06-22T07:06:52.988965Z","shell.execute_reply.started":"2022-06-22T07:06:52.981274Z","shell.execute_reply":"2022-06-22T07:06:52.987837Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"grid_search.fit(X_train_scaled, y_train);","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:07:02.154071Z","iopub.execute_input":"2022-06-22T07:07:02.154796Z","iopub.status.idle":"2022-06-22T07:07:24.062158Z","shell.execute_reply.started":"2022-06-22T07:07:02.154746Z","shell.execute_reply":"2022-06-22T07:07:24.060885Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"# printing the optimal accuracy score and hyperparameters\nprint('Best Accuracy that can be achivied is',grid_search.best_score_,'using',grid_search.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:07:42.981545Z","iopub.execute_input":"2022-06-22T07:07:42.982341Z","iopub.status.idle":"2022-06-22T07:07:42.988430Z","shell.execute_reply.started":"2022-06-22T07:07:42.982283Z","shell.execute_reply":"2022-06-22T07:07:42.987463Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"rf_tuned = RandomForestClassifier(max_depth= 8, max_features= 5, n_estimators= 50)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:07:43.809606Z","iopub.execute_input":"2022-06-22T07:07:43.810388Z","iopub.status.idle":"2022-06-22T07:07:43.816368Z","shell.execute_reply.started":"2022-06-22T07:07:43.810323Z","shell.execute_reply":"2022-06-22T07:07:43.815419Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"rf_tuned.fit(X_train_scaled,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:07:47.089576Z","iopub.execute_input":"2022-06-22T07:07:47.090291Z","iopub.status.idle":"2022-06-22T07:07:47.202185Z","shell.execute_reply.started":"2022-06-22T07:07:47.090237Z","shell.execute_reply":"2022-06-22T07:07:47.200786Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"rf_tuned_score = rf_tuned.score(X_test_scaled,y_test)  \ntempResult_df = pd.DataFrame({'Model': ['Random Forest Tuned'], 'Accuracy' : rf_tuned_score*100})\nresult_df = pd.concat([result_df,tempResult_df]).drop_duplicates()\nresult_df\nresult_df","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:07:48.156230Z","iopub.execute_input":"2022-06-22T07:07:48.156709Z","iopub.status.idle":"2022-06-22T07:07:48.188461Z","shell.execute_reply.started":"2022-06-22T07:07:48.156638Z","shell.execute_reply":"2022-06-22T07:07:48.187705Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"result_df","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:07:50.454192Z","iopub.execute_input":"2022-06-22T07:07:50.454687Z","iopub.status.idle":"2022-06-22T07:07:50.466815Z","shell.execute_reply.started":"2022-06-22T07:07:50.454596Z","shell.execute_reply":"2022-06-22T07:07:50.465803Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"# KNN - \"Best Performing ALgorithm\"\nfrom sklearn import metrics\nprint('KNN')\npd.DataFrame(metrics.confusion_matrix(y_test,knn_predict))","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:07:51.801163Z","iopub.execute_input":"2022-06-22T07:07:51.801575Z","iopub.status.idle":"2022-06-22T07:07:51.817106Z","shell.execute_reply.started":"2022-06-22T07:07:51.801540Z","shell.execute_reply":"2022-06-22T07:07:51.815711Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"#PLOTTING MODEL ACCURACY\nfig=plt.figure(figsize=(12,5))\nfig.suptitle('MODELS ACCURACY COMPARISION',size = 12,style='italic')\nsns.barplot(result_df['Model'],result_df['Accuracy']);","metadata":{"execution":{"iopub.status.busy":"2022-06-22T07:07:52.806872Z","iopub.execute_input":"2022-06-22T07:07:52.807482Z","iopub.status.idle":"2022-06-22T07:07:53.036927Z","shell.execute_reply.started":"2022-06-22T07:07:52.807427Z","shell.execute_reply":"2022-06-22T07:07:53.035727Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}