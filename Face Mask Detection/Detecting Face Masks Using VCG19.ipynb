{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **FACE MASK DETECTION USING VCG19**\nThe Datasets used are:\n1. [Face Mask Detection](https://www.kaggle.com/datasets/andrewmvd/face-mask-detection),uploaded by Larxel on Kaggle.\n2. [Face Mask Detection ~12K Images Dataset](https://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset) ,uploaded by Ashish Jangra on Kaggle.\n\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-07-15T07:13:10.179201Z","iopub.execute_input":"2022-07-15T07:13:10.179535Z","iopub.status.idle":"2022-07-15T07:13:14.839253Z","shell.execute_reply.started":"2022-07-15T07:13:10.179493Z","shell.execute_reply":"2022-07-15T07:13:14.838524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Installing Requirements*","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom scipy.spatial import distance\nimport matplotlib.pyplot as plt\n\nfrom keras.applications.vgg19 import VGG19,preprocess_input\nfrom keras import Sequential\nfrom keras.layers import Flatten,Dense\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:13:48.167923Z","iopub.execute_input":"2022-07-15T07:13:48.168496Z","iopub.status.idle":"2022-07-15T07:13:54.427577Z","shell.execute_reply.started":"2022-07-15T07:13:48.168456Z","shell.execute_reply":"2022-07-15T07:13:54.426807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Loading The Data*","metadata":{}},{"cell_type":"code","source":"train_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Train'\ntest_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Test'\nval_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Validation'","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:13:57.434300Z","iopub.execute_input":"2022-07-15T07:13:57.434625Z","iopub.status.idle":"2022-07-15T07:13:57.443790Z","shell.execute_reply.started":"2022-07-15T07:13:57.434582Z","shell.execute_reply":"2022-07-15T07:13:57.443043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Cascade Classifier*\n[OpenCV Cascade Classifier Documentation](https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html)","metadata":{}},{"cell_type":"code","source":"def sigmoid(x):\n    return 1/(1+np.exp(-x))\n\ndef face_detector(face_image_path):\n    face_model = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt.xml\")\n    img = cv2.imread(face_image_path)\n    img_gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n    img_color = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n    faces = face_model.detectMultiScale3(img, minNeighbors=6,outputRejectLevels =True)\n    faces_probs = sigmoid(faces[-1])\n    for i,d in enumerate(faces[0]):\n        (x,y,w,h) = d\n        if faces_probs[i]>0.95:\n            cv2.rectangle(img_color,(x,y),(x+w,y+h),(0,0,255),1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(img_color)\n\n    \nface_detector(\"../input/face-mask-detection/images/maksssksksss242.png\")","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:13:59.972189Z","iopub.execute_input":"2022-07-15T07:13:59.972457Z","iopub.status.idle":"2022-07-15T07:14:00.908464Z","shell.execute_reply.started":"2022-07-15T07:13:59.972427Z","shell.execute_reply":"2022-07-15T07:14:00.907718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Data Agumentation*","metadata":{}},{"cell_type":"code","source":"def data_agument(train_dir,val_dir,test_dir,target_size_ = (128,128),zoom_range_ = 0.2,shear_range_=0.2,batch_size_ = 32,class_mode_ = 'binary'):\n    train_datagen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, zoom_range=zoom_range_,shear_range=shear_range_)\n    train_generator = train_datagen.flow_from_directory(directory=train_dir,target_size=target_size_,class_mode='binary',batch_size=batch_size_)\n\n    val_datagen = ImageDataGenerator(rescale=1.0/255)\n    val_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=target_size_,class_mode=class_mode_,batch_size=batch_size_)\n\n    test_datagen = ImageDataGenerator(rescale=1.0/255)\n    test_generator = train_datagen.flow_from_directory(directory=test_dir,target_size=target_size_,class_mode=class_mode_,batch_size=batch_size_)\n    return train_generator,val_generator,test_generator\ntrain_gen,val_gen,test_gen = data_agument(train_dir,val_dir,test_dir)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:14:04.035144Z","iopub.execute_input":"2022-07-15T07:14:04.035402Z","iopub.status.idle":"2022-07-15T07:14:06.515435Z","shell.execute_reply.started":"2022-07-15T07:14:04.035372Z","shell.execute_reply":"2022-07-15T07:14:06.513837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Build Model and Train*","metadata":{}},{"cell_type":"code","source":"def build_train_model(train_generator,test_generator,val_generator,epoch = 25):\n    vgg19 = VGG19(weights = 'imagenet',include_top = False,input_shape = (128,128,3))\n    for layer in vgg19.layers:\n        layer.trainable = False\n\n    model = Sequential()\n    model.add(vgg19)\n    model.add(Flatten())\n    model.add(Dense(1,activation = 'sigmoid'))\n    model.summary()\n\n    model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n\n    history = model.fit_generator(generator=train_generator,\n                                  steps_per_epoch=len(train_generator)//32,\n                                  epochs=epoch,validation_data=val_generator,\n                                  validation_steps=len(val_generator)//32)\n    model.save('masknet.h5')\n    return history,model\nhistory,model = build_train_model(train_gen,test_gen,test_gen)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:14:09.073811Z","iopub.execute_input":"2022-07-15T07:14:09.074290Z","iopub.status.idle":"2022-07-15T07:15:47.208163Z","shell.execute_reply.started":"2022-07-15T07:14:09.074252Z","shell.execute_reply":"2022-07-15T07:15:47.203632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Evaluatation*","metadata":{}},{"cell_type":"code","source":"def evaluate(test_generator):\n    accuracy = model.evaluate_generator(test_generator)\n    print(\"VGG19 MODEL ACCURACY : \"+ str(accuracy[1]))\n    return accuracy\naccuracy = evaluate(test_gen)    ","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:15:53.777146Z","iopub.execute_input":"2022-07-15T07:15:53.777454Z","iopub.status.idle":"2022-07-15T07:16:03.732784Z","shell.execute_reply.started":"2022-07-15T07:15:53.777420Z","shell.execute_reply":"2022-07-15T07:16:03.731992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Ploting Loss and Accuracy*","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.title('---: Model Loss :---')\nplt.ylabel('<-------Loss---------->')\nplt.xlabel('<-------Epoch--------->')\nplt.legend(['Loss'], loc='lower right')\nplt.show()\n\nplt.plot(history.history['accuracy'])\nplt.title('---: Model Accuracy :---')\nplt.ylabel('<--------Accuracy-------->')\nplt.xlabel('<--------Epoch---------->')\nplt.legend(['Accuracy'], loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:16:13.313720Z","iopub.execute_input":"2022-07-15T07:16:13.314310Z","iopub.status.idle":"2022-07-15T07:16:13.680498Z","shell.execute_reply.started":"2022-07-15T07:16:13.314271Z","shell.execute_reply":"2022-07-15T07:16:13.679861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Single Image Prediction*","metadata":{}},{"cell_type":"code","source":"def predict(sample_img_path):\n    mask_label = {0:'MASK',1:'NO MASK'}\n    dist_label = {0:(0,255,0),1:(255,0,0)}\n    face_model = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt2.xml\")\n    img = cv2.imread(sample_img_path)\n    img_gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n    img_color = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n    faces = face_model.detectMultiScale3(img, minNeighbors=6,outputRejectLevels =True)\n    print(faces[0])\n    print(faces[-1])\n    \n    faces_probs = sigmoid(faces[-1])\n    print(faces_probs)\n    for i,d in enumerate(faces[0]):\n        (x,y,w,h) = d\n        if faces_probs[i]>0.95:\n            cv2.rectangle(img_color,(x,y),(x+w,y+h),(0,0,255),4)\n    plt.figure(figsize=(10,10))\n    plt.imshow(img_color)\n    plt.show()\n    for i in range(len(faces[0])):\n        if faces_probs[i]>0.95:\n            (x,y,w,h) = faces[0][i]\n            crop = img_color[y:y+h,x:x+w]\n            crop = cv2.resize(crop,(128,128))\n            crop = np.reshape(crop,[1,128,128,3])/255.0\n            mask_result = model.predict(crop)\n            #print(type(mask_result))\n            #print(mask_result)\n            cv2.putText(img_color,mask_label[np.round(mask_result[0][0])] +\" \"+ str(faces_probs[i]) ,(x, y-10),\n            cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[np.round(mask_result[0][0])],2)\n            cv2.rectangle(img_color,(x,y),(x+w,y+h),dist_label[np.round(mask_result[0][0])],2)\n    plt.figure(figsize=(10,10))\n    plt.imshow(img_color)\n    plt.show()\npredict(\"../input/face-mask-detection/images/maksssksksss243.png\")","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:17:07.727359Z","iopub.execute_input":"2022-07-15T07:17:07.727624Z","iopub.status.idle":"2022-07-15T07:17:08.595111Z","shell.execute_reply.started":"2022-07-15T07:17:07.727593Z","shell.execute_reply":"2022-07-15T07:17:08.594317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"ACCURACY OF VCG19 MODEL : {} \".format(accuracy[1]))","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:17:40.678098Z","iopub.execute_input":"2022-07-15T07:17:40.678811Z","iopub.status.idle":"2022-07-15T07:17:40.683591Z","shell.execute_reply.started":"2022-07-15T07:17:40.678771Z","shell.execute_reply":"2022-07-15T07:17:40.682890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}